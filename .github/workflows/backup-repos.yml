name: Repository Backup to Azure Blob Storage

on:
    workflow_dispatch:
        inputs:
            force_cleanup:
                description: "Force cleanup of old backups"
                required: false
                default: false
                type: boolean
            retention_days:
                description: "Retention period in days (default: 30)"
                required: false
                default: "30"
                type: string
    schedule:
        - cron: "0 2 * * *" # Daily at 2:00 AM UTC

env:
    AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
    AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
    WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
    BACKUP_TOKEN: ${{ secrets.BACKUP_TOKEN }}
    CONTAINER_NAME: "repo-backups"
    MAX_RETRIES: 3
    RETRY_DELAY: 30
    RETENTION_DAYS: ${{ github.event.inputs.retention_days || '30' }}

jobs:
    validate-config:
        runs-on: ubuntu-latest
        outputs:
            config-valid: ${{ steps.validate.outputs.valid }}
        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Validate configuration
              id: validate
              run: |
                  echo "Validating backup configuration..."

                  # Check required secrets
                  if [ -z "$AZURE_STORAGE_ACCOUNT" ]; then
                    echo "‚ùå AZURE_STORAGE_ACCOUNT secret is missing"
                    exit 1
                  fi

                  if [ -z "$AZURE_STORAGE_KEY" ]; then
                    echo "‚ùå AZURE_STORAGE_KEY secret is missing"
                    exit 1
                  fi

                  # Check repos.txt exists and is valid
                  if [ ! -f "repos.txt" ]; then
                    echo "‚ùå repos.txt file not found"
                    exit 1
                  fi

                  # Validate repository URLs
                  invalid_repos=0
                  while IFS= read -r line; do
                    # Skip comments and empty lines
                    if [[ "$line" =~ ^[[:space:]]*# ]] || [[ -z "${line// }" ]]; then
                      continue
                    fi
                    
                    # Basic URL validation
                    if [[ ! "$line" =~ ^https?:// ]]; then
                      echo "‚ùå Invalid repository URL: $line"
                      invalid_repos=$((invalid_repos + 1))
                    fi
                  done < repos.txt

                  if [ $invalid_repos -gt 0 ]; then
                    echo "‚ùå Found $invalid_repos invalid repository URLs"
                    exit 1
                  fi

                  # Count valid repositories
                  repo_count=$(grep -v '^[[:space:]]*#' repos.txt | grep -v '^[[:space:]]*$' | wc -l)
                  echo "‚úÖ Configuration valid. Found $repo_count repositories to backup."
                  echo "valid=true" >> $GITHUB_OUTPUT

    backup-repositories:
        runs-on: ubuntu-latest
        needs: validate-config
        if: needs.validate-config.outputs.config-valid == 'true'
        timeout-minutes: 480 # 8 hours max

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Install dependencies
              run: |
                  set -euo pipefail

                  echo "üì¶ Installing Azure CLI..."
                  if ! curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash; then
                    echo "‚ùå Failed to install Azure CLI"
                    exit 1
                  fi

                  echo "üì¶ Installing additional tools..."
                  if ! sudo apt-get update; then
                    echo "‚ùå Failed to update package list"
                    exit 1
                  fi

                  if ! sudo apt-get install -y jq curl parallel bc; then
                    echo "‚ùå Failed to install required packages"
                    exit 1
                  fi

                  # Verify installations
                  echo "‚úÖ Verifying installations..."
                  az --version | head -1
                  jq --version
                  bc --version | head -1

                  echo "‚úÖ All dependencies installed successfully"

            - name: Setup Azure CLI
              run: |
                  set -euo pipefail

                  # Enhanced logging function
                  log() {
                    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [$1] ${*:2}"
                  }

                  log "INFO" "üîê Testing Azure CLI authentication..."

                  # Validate secret format (basic checks)
                  if [ -z "$AZURE_STORAGE_ACCOUNT" ]; then
                    log "ERROR" "AZURE_STORAGE_ACCOUNT is empty"
                    exit 1
                  fi

                  if [ -z "$AZURE_STORAGE_KEY" ]; then
                    log "ERROR" "AZURE_STORAGE_KEY is empty"
                    exit 1
                  fi

                  # Check storage account name format
                  if [[ ! "$AZURE_STORAGE_ACCOUNT" =~ ^[a-z0-9]{3,24}$ ]]; then
                    log "WARN" "Storage account name format may be invalid (should be 3-24 lowercase letters/numbers)"
                  fi

                  log "INFO" "Storage account: $AZURE_STORAGE_ACCOUNT"
                  log "INFO" "Storage key length: ${#AZURE_STORAGE_KEY} characters"

                  # Test 1: Simple container list (most reliable test)
                  log "INFO" "Test 1: Listing containers to verify authentication..."

                  if az storage container list \
                    --account-name "$AZURE_STORAGE_ACCOUNT" \
                    --account-key "$AZURE_STORAGE_KEY" \
                    --output table 2>&1; then
                    log "INFO" "‚úÖ Container list successful - authentication working"
                  else
                    log "ERROR" "‚ùå Container list failed. Let's try more detailed diagnosis..."
                    
                    # Test 2: Try without account key to see if it's a key issue
                    log "INFO" "Test 2: Testing account name resolution..."
                    if az storage account show --name "$AZURE_STORAGE_ACCOUNT" --output table 2>&1; then
                      log "ERROR" "Storage account exists but key authentication failed"
                      log "ERROR" "Possible issues:"
                      log "ERROR" "  1. Storage key is incorrect or expired"
                      log "ERROR" "  2. Storage key has special characters causing parsing issues"
                      log "ERROR" "  3. Storage account has restricted access policies"
                    else
                      log "ERROR" "Cannot access storage account information"
                      log "ERROR" "Possible issues:"
                      log "ERROR" "  1. Storage account name is incorrect"
                      log "ERROR" "  2. Storage account is in different subscription/region"
                      log "ERROR" "  3. Storage account does not exist"
                      log "ERROR" "  4. Insufficient permissions to read account metadata"
                    fi
                    
                    # Test 3: Show detailed Azure CLI error
                    log "INFO" "Test 3: Detailed error output..."
                    az storage container list \
                      --account-name "$AZURE_STORAGE_ACCOUNT" \
                      --account-key "$AZURE_STORAGE_KEY" \
                      --output json \
                      --debug 2>&1 | head -20 || true
                      
                    exit 1
                  fi

                  # Create/verify container
                  log "INFO" "üì¶ Ensuring backup container exists: $CONTAINER_NAME"

                  # Check if container exists
                  container_exists=$(az storage container exists \
                    --account-name "$AZURE_STORAGE_ACCOUNT" \
                    --account-key "$AZURE_STORAGE_KEY" \
                    --name "$CONTAINER_NAME" \
                    --query "exists" \
                    --output tsv 2>/dev/null || echo "false")

                  if [ "$container_exists" = "true" ]; then
                    log "INFO" "‚úÖ Container '$CONTAINER_NAME' already exists"
                  else
                    log "INFO" "üìÅ Creating container '$CONTAINER_NAME'..."
                    if az storage container create \
                      --account-name "$AZURE_STORAGE_ACCOUNT" \
                      --account-key "$AZURE_STORAGE_KEY" \
                      --name "$CONTAINER_NAME" \
                      --public-access off \
                      --output none 2>&1; then
                      log "INFO" "‚úÖ Container created successfully"
                    else
                      log "ERROR" "‚ùå Failed to create container. Error details:"
                      az storage container create \
                        --account-name "$AZURE_STORAGE_ACCOUNT" \
                        --account-key "$AZURE_STORAGE_KEY" \
                        --name "$CONTAINER_NAME" \
                        --public-access off 2>&1 || true
                      exit 1
                    fi
                  fi

                  log "INFO" "üéâ Azure CLI setup completed successfully"

            - name: Backup repositories
              run: |
                  set -euo pipefail

                  # Global variables
                  DATE_STR=$(date +%Y%m%d_%H%M%S)
                  TEMP_BASE_DIR=$(mktemp -d)
                  SUCCESSFUL_BACKUPS=()
                  FAILED_BACKUPS=()
                  BACKUP_STATS=""

                  # Cleanup on exit
                  trap 'cleanup_and_exit' EXIT

                  cleanup_and_exit() {
                    echo "üßπ Cleaning up temporary files..."
                    rm -rf "$TEMP_BASE_DIR"
                  }

                  # Enhanced logging function
                  log() {
                    local level="$1"
                    shift
                    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [$level] $*"
                  }

                  # Retry function with exponential backoff (simplified)
                  retry_command() {
                    local max_attempts="$1"
                    local delay="$2"
                    shift 2
                    local attempt=1
                    
                    while [ $attempt -le $max_attempts ]; do
                      log "INFO" "Executing command (attempt $attempt of $max_attempts)"
                      
                      if "$@"; then
                        return 0
                      else
                        if [ $attempt -eq $max_attempts ]; then
                          log "ERROR" "Command failed after $max_attempts attempts"
                          return 1
                        fi
                        
                        local wait_time=$((delay * attempt))
                        log "WARN" "Command failed, retrying in ${wait_time}s..."
                        sleep $wait_time
                        attempt=$((attempt + 1))
                      fi
                    done
                  }

                  # Enhanced webhook function with retry
                  send_webhook() {
                    local success="$1"
                    local message="$2"
                    local details="$3"
                    
                    if [ -z "$WEBHOOK_URL" ]; then
                      log "INFO" "No webhook URL configured, skipping notification"
                      return 0
                    fi
                    
                    # Sanitize message for JSON
                    local safe_message=$(echo "$message" | jq -Rs .)
                    
                    local payload=$(jq -n \
                      --argjson success "$success" \
                      --argjson message "$safe_message" \
                      --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%S.000Z)" \
                      --arg workflow "repository-backup" \
                      --argjson details "$details" \
                      '{
                        success: $success,
                        message: $message,
                        timestamp: $timestamp,
                        workflow: $workflow,
                        details: $details
                      }')
                    
                    log "INFO" "Sending webhook notification..."
                    
                    local response_file=$(mktemp)
                    local http_code
                    
                    http_code=$(curl -s -w "%{http_code}" \
                      -X POST "$WEBHOOK_URL" \
                      -H "Content-Type: application/json" \
                      -H "User-Agent: GitHub-Actions-Backup/1.0" \
                      -d "$payload" \
                      --max-time 30 \
                      --connect-timeout 10 \
                      --retry 2 \
                      --retry-delay 5 \
                      -o "$response_file")
                    
                    if [ "$http_code" -ge 200 ] && [ "$http_code" -lt 300 ]; then
                      log "INFO" "Webhook sent successfully (HTTP $http_code)"
                    else
                      log "ERROR" "Webhook failed (HTTP $http_code): $(cat "$response_file")"
                    fi
                    
                    rm -f "$response_file"
                  }

                  # Enhanced repository cloning
                  clone_repository() {
                    local repo_url="$1"
                    local temp_dir="$2"
                    local repo_name=$(basename "$repo_url" .git)
                    local repo_path="$temp_dir/${repo_name}_${DATE_STR}"
                    
                    log "INFO" "Cloning repository: $repo_name"
                    
                    # Prepare clone URL (avoid token leakage in logs)
                    local clone_url="$repo_url"
                    if [ -n "$BACKUP_TOKEN" ] && [[ "$repo_url" == *"github.com"* ]]; then
                      clone_url="https://oauth2:${BACKUP_TOKEN}@$(echo "$repo_url" | sed 's|https://||')"
                    fi
                    
                    # Clone with full history (proper backup)
                    if git clone --mirror --quiet "$clone_url" "$repo_path" 2>/dev/null; then
                      # Verify clone integrity
                      if [ -d "$repo_path" ] && [ -d "$repo_path/refs" ]; then
                        local ref_count=$(find "$repo_path/refs" -type f | wc -l)
                        log "INFO" "Successfully cloned $repo_name ($ref_count refs)"
                        echo "$repo_path"
                      else
                        log "ERROR" "Clone verification failed for $repo_name"
                        rm -rf "$repo_path"
                        return 1
                      fi
                    else
                      log "ERROR" "Failed to clone $repo_name"
                      return 1
                    fi
                  }

                  # Enhanced upload with validation
                  upload_to_blob_storage() {
                    local repo_path="$1"
                    local blob_name="$2"
                    local repo_name=$(basename "$repo_path")
                    
                    log "INFO" "Creating backup archive: $blob_name"
                    
                    if [ ! -d "$repo_path" ]; then
                      log "ERROR" "Repository path does not exist: $repo_path"
                      return 1
                    fi
                    
                    # Calculate repository size
                    local repo_size=$(du -sb "$repo_path" 2>/dev/null | cut -f1)
                    if [ -z "$repo_size" ] || [ "$repo_size" -eq 0 ]; then
                      log "ERROR" "Could not determine repository size for $repo_name"
                      return 1
                    fi
                    
                    log "INFO" "Repository size: $(numfmt --to=iec $repo_size 2>/dev/null || echo "${repo_size} bytes")"
                    
                    # Create compressed archive
                    local tar_path="${repo_path}.tar.gz"
                    log "INFO" "Creating archive: $tar_path"
                    
                    if ! tar -czf "$tar_path" -C "$(dirname "$repo_path")" "$(basename "$repo_path")" 2>/dev/null; then
                      log "ERROR" "Failed to create archive for $repo_name"
                      return 1
                    fi
                    
                    if [ ! -f "$tar_path" ]; then
                      log "ERROR" "Archive file was not created: $tar_path"
                      return 1
                    fi
                    
                    local archive_size=$(stat -c%s "$tar_path" 2>/dev/null)
                    if [ -z "$archive_size" ] || [ "$archive_size" -eq 0 ]; then
                      log "ERROR" "Archive appears to be empty or unreadable"
                      rm -f "$tar_path"
                      return 1
                    fi
                    
                    # Calculate compression ratio safely
                    local compression_ratio="N/A"
                    if command -v bc >/dev/null 2>&1 && [ "$repo_size" -gt 0 ]; then
                      compression_ratio=$(echo "scale=1; $archive_size * 100 / $repo_size" | bc -l 2>/dev/null || echo "N/A")
                    fi
                    
                    log "INFO" "Archive size: $(numfmt --to=iec $archive_size 2>/dev/null || echo "${archive_size} bytes") (${compression_ratio}% of original)"
                    
                    # Test Azure CLI connectivity first
                    log "INFO" "Testing Azure connection..."
                    if ! az storage account show \
                      --name "$AZURE_STORAGE_ACCOUNT" \
                      --query "name" \
                      --output tsv >/dev/null 2>&1; then
                      log "ERROR" "Cannot access Azure storage account: $AZURE_STORAGE_ACCOUNT"
                      rm -f "$tar_path"
                      return 1
                    fi
                    
                    # Upload with retries
                    local upload_start=$(date +%s)
                    local upload_success=false
                    local attempt=1
                    local max_attempts=3
                    
                    while [ $attempt -le $max_attempts ] && [ "$upload_success" = "false" ]; do
                      log "INFO" "Upload attempt $attempt of $max_attempts for $blob_name"
                      
                      # Create metadata as separate variables to avoid quoting issues
                      local backup_date_meta="backup_date=$(date -u +%Y-%m-%dT%H:%M:%S.000Z)"
                      local ttl_meta="ttl_days=$RETENTION_DAYS"
                      local size_meta="repo_size=$repo_size"
                      local archive_meta="archive_size=$archive_size"
                      
                      # Execute upload command directly (avoiding complex retry function)
                      if az storage blob upload \
                        --account-name "$AZURE_STORAGE_ACCOUNT" \
                        --account-key "$AZURE_STORAGE_KEY" \
                        --container-name "$CONTAINER_NAME" \
                        --name "$blob_name" \
                        --file "$tar_path" \
                        --overwrite \
                        --content-type "application/gzip" \
                        --metadata "$backup_date_meta" "$ttl_meta" "$size_meta" "$archive_meta" \
                        --no-progress \
                        --output none 2>/dev/null; then
                        
                        log "INFO" "Upload command completed for $blob_name"
                        upload_success=true
                      else
                        log "WARN" "Upload attempt $attempt failed for $blob_name"
                        if [ $attempt -lt $max_attempts ]; then
                          local wait_time=$((5 * attempt))
                          log "INFO" "Waiting ${wait_time}s before retry..."
                          sleep $wait_time
                        fi
                        attempt=$((attempt + 1))
                      fi
                    done
                    
                    if [ "$upload_success" = "false" ]; then
                      log "ERROR" "Failed to upload $blob_name after $max_attempts attempts"
                      rm -f "$tar_path"
                      return 1
                    fi
                    
                    local upload_duration=$(($(date +%s) - upload_start))
                    
                    # Calculate upload speed safely
                    local upload_speed="N/A"
                    if command -v bc >/dev/null 2>&1 && [ "$upload_duration" -gt 0 ]; then
                      upload_speed=$(echo "scale=2; $archive_size / 1024 / 1024 / $upload_duration" | bc -l 2>/dev/null || echo "N/A")
                    fi
                    
                    log "INFO" "Upload completed for $blob_name (${upload_speed} MB/s)"
                    
                    # Verify upload exists
                    log "INFO" "Verifying upload of $blob_name..."
                    if az storage blob exists \
                      --account-name "$AZURE_STORAGE_ACCOUNT" \
                      --account-key "$AZURE_STORAGE_KEY" \
                      --container-name "$CONTAINER_NAME" \
                      --name "$blob_name" \
                      --output none 2>/dev/null; then
                      
                      log "INFO" "Successfully uploaded and verified $blob_name"
                      rm -f "$tar_path"
                      echo "$repo_size,$archive_size,$upload_duration"
                      return 0
                    else
                      log "ERROR" "Upload verification failed for $blob_name - blob does not exist"
                      rm -f "$tar_path"
                      return 1
                    fi
                  }

                  # Enhanced cleanup with safety checks
                  cleanup_old_backups() {
                    log "INFO" "Starting cleanup of backups older than $RETENTION_DAYS days..."
                    
                    local cutoff_date=$(date -u -d "$RETENTION_DAYS days ago" +%Y-%m-%dT%H:%M:%S.000Z)
                    local deleted_count=0
                    local total_freed=0
                    
                    # Get old backups
                    local old_blobs=$(az storage blob list \
                      --account-name "$AZURE_STORAGE_ACCOUNT" \
                      --account-key "$AZURE_STORAGE_KEY" \
                      --container-name "$CONTAINER_NAME" \
                      --query "[?metadata.backup_date && metadata.backup_date < '$cutoff_date'].{name:name,size:properties.contentLength}" \
                      --output json)
                    
                    if [ "$old_blobs" != "[]" ]; then
                      echo "$old_blobs" | jq -r '.[] | "\(.name) \(.size)"' | while read -r blob_name blob_size; do
                        if [ -n "$blob_name" ]; then
                          log "INFO" "Deleting old backup: $blob_name ($(numfmt --to=iec $blob_size))"
                          
                          if az storage blob delete \
                            --account-name "$AZURE_STORAGE_ACCOUNT" \
                            --account-key "$AZURE_STORAGE_KEY" \
                            --container-name "$CONTAINER_NAME" \
                            --name "$blob_name" \
                            --output none; then
                            
                            deleted_count=$((deleted_count + 1))
                            total_freed=$((total_freed + blob_size))
                          else
                            log "ERROR" "Failed to delete $blob_name"
                          fi
                        fi
                      done
                      
                      log "INFO" "Cleanup completed: $deleted_count files deleted, $(numfmt --to=iec $total_freed) freed"
                    else
                      log "INFO" "No old backups found to clean up"
                    fi
                  }

                  # Main backup process
                  log "INFO" "üöÄ Starting repository backup process..."

                  # Read and validate repository list
                  repos=$(grep -v '^[[:space:]]*#' repos.txt | grep -v '^[[:space:]]*$' | sort -u)
                  repo_count=$(echo "$repos" | wc -l)

                  log "INFO" "Processing $repo_count repositories..."

                  # Process repositories
                  backup_start=$(date +%s)
                  total_size=0
                  total_compressed=0

                  echo "$repos" | while IFS= read -r repo_url; do
                    if [ -n "$repo_url" ]; then
                      repo_start=$(date +%s)
                      repo_name=$(basename "$repo_url" .git)
                      
                      log "INFO" "üì¶ Processing: $repo_name"
                      
                      # Create isolated temp directory for this repo
                      repo_temp_dir=$(mktemp -d -p "$TEMP_BASE_DIR")
                      
                      # Clone repository
                      if repo_path=$(clone_repository "$repo_url" "$repo_temp_dir"); then
                        blob_name="${repo_name}_${DATE_STR}.tar.gz"
                        
                        log "INFO" "Repository cloned successfully: $repo_path"
                        log "INFO" "Starting upload process for blob: $blob_name"
                        
                        # Upload to Azure
                        if backup_stats=$(upload_to_blob_storage "$repo_path" "$blob_name"); then
                          log "INFO" "Upload function returned: $backup_stats"
                          
                          # Parse the returned stats
                          if [[ "$backup_stats" =~ ^[0-9]+,[0-9]+,[0-9]+$ ]]; then
                            IFS=',' read -r repo_size archive_size upload_time <<< "$backup_stats"
                            
                            repo_duration=$(($(date +%s) - repo_start))
                            
                            SUCCESSFUL_BACKUPS+=($(jq -n \
                              --arg repo "$repo_url" \
                              --arg blob_name "$blob_name" \
                              --argjson repo_size "$repo_size" \
                              --argjson archive_size "$archive_size" \
                              --argjson duration "$repo_duration" \
                              '{repo: $repo, blob_name: $blob_name, repo_size: $repo_size, archive_size: $archive_size, duration: $duration}'))
                            
                            total_size=$((total_size + repo_size))
                            total_compressed=$((total_compressed + archive_size))
                            
                            log "INFO" "‚úÖ Successfully backed up $repo_name in ${repo_duration}s"
                          else
                            log "ERROR" "Invalid backup stats format returned: '$backup_stats'"
                            FAILED_BACKUPS+=($(jq -n \
                              --arg repo "$repo_url" \
                              --arg error "Invalid backup stats returned" \
                              '{repo: $repo, error: $error}'))
                          fi
                        else
                          upload_exit_code=$?
                          log "ERROR" "Upload function failed with exit code: $upload_exit_code"
                          FAILED_BACKUPS+=($(jq -n \
                            --arg repo "$repo_url" \
                            --arg error "Upload failed (exit code: $upload_exit_code)" \
                            '{repo: $repo, error: $error}'))
                          log "ERROR" "‚ùå Failed to upload $repo_name"
                        fi
                      else
                        clone_exit_code=$?
                        log "ERROR" "Clone function failed with exit code: $clone_exit_code"
                        FAILED_BACKUPS+=($(jq -n \
                          --arg repo "$repo_url" \
                          --arg error "Clone failed (exit code: $clone_exit_code)" \
                          '{repo: $repo, error: $error}'))
                        log "ERROR" "‚ùå Failed to clone $repo_name"
                      fi
                      
                      # Cleanup repo temp directory
                      rm -rf "$repo_temp_dir"
                    fi
                  done

                  # Cleanup old backups
                  if [ "${{ github.event.inputs.force_cleanup }}" = "true" ] || [ "$(date +%u)" = "7" ]; then
                    cleanup_old_backups
                  fi

                  # Calculate final statistics
                  backup_duration=$(($(date +%s) - backup_start))
                  successful_count=${#SUCCESSFUL_BACKUPS[@]}
                  failed_count=${#FAILED_BACKUPS[@]}

                  log "INFO" "üìä Backup Summary:"
                  log "INFO" "  - Duration: $(date -u -d @$backup_duration +%H:%M:%S)"
                  log "INFO" "  - Successful: $successful_count"
                  log "INFO" "  - Failed: $failed_count"
                  log "INFO" "  - Total size: $(numfmt --to=iec $total_size)"
                  log "INFO" "  - Compressed: $(numfmt --to=iec $total_compressed)"

                  if [ $total_size -gt 0 ]; then
                    compression_ratio=$(echo "scale=1; $total_compressed * 100 / $total_size" | bc -l)
                    log "INFO" "  - Compression: ${compression_ratio}%"
                  fi

                  # Send final webhook
                  if [ $failed_count -gt 0 ]; then
                    failed_json=$(printf '%s\n' "${FAILED_BACKUPS[@]}" | jq -s .)
                    successful_json=$(printf '%s\n' "${SUCCESSFUL_BACKUPS[@]}" | jq -s .)
                    
                    details=$(jq -n \
                      --argjson successful "$successful_count" \
                      --argjson failed "$failed_count" \
                      --argjson duration "$backup_duration" \
                      --argjson total_size "$total_size" \
                      --argjson total_compressed "$total_compressed" \
                      --argjson failed_repos "$failed_json" \
                      --argjson successful_repos "$successful_json" \
                      '{
                        successful: $successful,
                        failed: $failed,
                        duration: $duration,
                        total_size: $total_size,
                        total_compressed: $total_compressed,
                        failed_repos: $failed_repos,
                        successful_repos: $successful_repos
                      }')
                    
                    send_webhook false "Backup completed with $failed_count failures out of $repo_count repositories" "$details"
                    exit 1
                  else
                    successful_json=$(printf '%s\n' "${SUCCESSFUL_BACKUPS[@]}" | jq -s .)
                    
                    details=$(jq -n \
                      --argjson successful "$successful_count" \
                      --argjson duration "$backup_duration" \
                      --argjson total_size "$total_size" \
                      --argjson total_compressed "$total_compressed" \
                      --argjson backed_up_repos "$successful_json" \
                      '{
                        successful: $successful,
                        duration: $duration,
                        total_size: $total_size,
                        total_compressed: $total_compressed,
                        backed_up_repos: $backed_up_repos
                      }')
                    
                    send_webhook true "All $successful_count repositories backed up successfully" "$details"
                  fi

                  log "INFO" "üéâ Backup process completed successfully!"

            - name: Upload job artifacts
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: backup-logs-${{ github.run_number }}
                  path: |
                      /tmp/backup-*.log
                  retention-days: 7
